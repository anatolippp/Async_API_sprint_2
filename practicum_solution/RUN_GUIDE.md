# Пошаговый запуск стенда и проверок

Ниже пошаговая инструкция, рассчитанная на джуна-стажёра, как запустить весь комплект (инфраструктура, сидирование, бенчмарк, API, логи, Sentry и CI-проверки).

1. Убедитесь, что установлен Docker Compose v2 (`docker compose version`) и свободны порты 27017, 5432, 5601, 9200, 5044, 5000.
2. Перейдите в директорию `practicum_solution` внутри репозитория: `cd practicum_solution`.
3. Скопируйте файл окружения из шаблона: `cp env.example .env`.
4. Подготовьте переменные в `.env` **до запуска контейнеров**:
   - Зарегистрируйте бесплатный аккаунт в облачном Sentry (sentry.io), создайте проект типа **Python**, скопируйте выданный DSN (строка вида `https://<public>@<host>/<project>`), вставьте его в `SENTRY_DSN`. Если DSN впишете позже, контейнер `api` всё равно поднимется, но ошибки не уйдут в мониторинг до перезапуска с обновлённым `.env`.
   - Создайте бота в Telegram через BotFather (`/start` → `/newbot`), получите токен наподобие `123456:ABC-DEF...` и запишите его в `TELEGRAM_TOKEN`. Добавьте бота в нужный чат (или личный диалог), напишите любое сообщение и узнайте `TELEGRAM_CHAT_ID` (например, через `curl https://api.telegram.org/bot<token>/getUpdates` или бота @userinfobot) — вставьте ID в одноимённую переменную. Эти значения нужны workflow GitHub Actions; если оставить пустыми, шаг уведомления упадёт.
   - Остальные поля (`MONGO_URL`, `POSTGRES_DSN`, `DATASET_RECORDS`, `DATASET_BATCH`, `DATASET_SEED`) можно оставить как в шаблоне или поменять под ресурсы машины; в `MONGO_URL` уже добавлен `authSource=admin`, чтобы авторизация работала с root-пользователем, созданным контейнером.
5. Если машина слабая, уменьшите объём генерации, выставив `DATASET_RECORDS` (например, оставьте 100_000 или поставьте 1_000_000 вместо 10_000_000) и размер пачки `DATASET_BATCH` (например, 2000) — это уменьшит время сидирования.
6. Проверьте, что `MONGO_URL` и `POSTGRES_DSN` вас устраивают; по умолчанию они смотрят на контейнеры `mongo` и `postgres`, поднятые в том же compose, и используют авторизацию `app/app` через `authSource=admin` в MongoDB.
7. Убедитесь, что директория `reports/` в корне репозитория существует (она создаётся в репозитории заранее); в неё будет сохраняться отчёт бенчмарка с помощью volume `./reports:/app/reports`.
8. Запустите инфраструктуру, сидирование и бенчмарк одной командой: `docker compose up -d --build` — compose соберёт контейнер API, поднимет базы, выполнит `seed` и после завершения запустит `benchmark`.
9. Следите за прогрессом в логах сервисов `seed` и `benchmark`: `docker compose logs -f seed benchmark` — сидирование завершится сообщением об успешной вставке, затем стартует бенчмарк. Если `seed` упадёт (например, из‑за неправильного `MONGO_URL`), healthcheck не даст запуститься бенчмарку, поэтому сначала исправьте конфигурацию и перезапустите: `docker compose up --force-recreate seed benchmark`.
10. После окончания бенчмарка загляните в `reports/performance.md` (на хосте), чтобы увидеть средние и p95 задержки по сценариям чтения; файл создаётся или перезаписывается автоматически контейнером `benchmark` при условии, что `seed` отработал успешно и базы прошли healthcheck.
11. Убедитесь, что контейнеры `mongo`, `postgres`, `api`, `elasticsearch`, `logstash`, `kibana`, `filebeat` находятся в статусе `running`: `docker compose ps`.
12. Чтобы посмотреть приложение в действии, отправьте запросы к API (по умолчанию `http://localhost:5000`): например, `curl http://localhost:5000/api/v1/movies/{movie_id}/likes` вернёт счётчик лайков фильма.
13. Для работы Kibana откройте браузер на `http://localhost:5601`; первые логи появятся после стартов `api`, Filebeat и Logstash, которые парсят uvicorn-строки.
14. Если нужно обновить индексы или схему PostgreSQL вручную, загляните в `postgres-init.sql`, который исполняется при старте контейнера `postgres`.
15. Для проверки, что Sentry принимает события, спровоцируйте ошибку в API (например, запросом на несуществующий маршрут) и убедитесь, что событие появляется в проекте Sentry, чей DSN указан в `.env`.
16. Если требуется повторно наполнить базы другим объёмом, остановите текущие сервисы (`docker compose down -v`), поменяйте `DATASET_RECORDS`/`DATASET_BATCH` и снова запустите `docker compose up -d --build`.
17. При желании запустить API без всей инфраструктуры можно поднять только MongoDB и сам `api`: `docker compose up -d mongo api` — при этом сидирования не будет, и коллекции будут пустыми.
18. Для локальной разработки без Docker установите зависимости `pip install -r requirements.txt`, поднимите MongoDB/PostgreSQL вручную и запустите `uvicorn api.main:app --reload`; переменные окружения нужно задать через `.env` или экспортировать в систему.
19. CI-пайплайн на GitHub Actions настроен в `.github/workflows/practicum-ci.yml`; он срабатывает на push/pull_request в master и запускает wemake-python-styleguide (с HTML-отчётом), mypy, pytest в матрице Python 3.10–3.12 и отправляет уведомление в Telegram.
20. Чтобы воспроизвести проверки CI локально, выполните в `practicum_solution`: `pip install -r requirements.txt` (при необходимости через офлайн-колесо), затем `flake8 --format=html --htmldir=flake8-html-report`, `mypy .`, `pytest`.
21. Если `flake8` сообщает о нарушениях WPS, исправляйте по подсказкам, следя за типизацией и длиной строк; все правила описаны в `setup.cfg`.
22. После локальных правок прогоните `python -m compileall practicum_solution`, чтобы убедиться в отсутствии синтаксических ошибок перед коммитом.
23. Когда контейнеры больше не нужны, остановите их и удалите тома: `docker compose down -v`; это очистит данные и отчёты, так что следующий запуск сидирует с нуля.
24. Если при скачивании образов видите ошибки доступа, убедитесь, что используемые образы публичные (в compose сейчас только открытые) и что есть доступ в интернет; при отсутствии сети подтяните образы заранее или смените зеркала Docker.
25. Для ускорения бенчмарка на слабой машине можно временно выключить ELK и Filebeat, запустив только нужные сервисы: `docker compose up -d mongo postgres seed benchmark api`.
26. Любые изменения в `.env` требуют перезапуска зависящих контейнеров: `docker compose up -d --force-recreate api` (или `seed`/`benchmark`, если менялась генерация).
27. Если нужно почистить лог-индексы Elasticsearch, выполните `docker compose exec elasticsearch curl -X DELETE 'http://localhost:9200/filebeat-*'` и перезапустите Filebeat/Logstash; это полезно при смене grok-паттернов.
28. Все артефакты (отчёты, логи контейнеров) остаются на хосте; перед отправкой на ревью убедитесь, что `reports/performance.md` содержит свежие результаты последнего прогона.

