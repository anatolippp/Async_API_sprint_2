# Практикум. Хранилище лайков, рецензий и закладок

Папка содержит изолированную реализацию требований спринта: исследование выбора хранилища, docker-compose для инфраструктуры, прототип API и CI-конфигурацию. Все материалы находятся только в этой директории, чтобы не затрагивать остальную часть репозитория.

## Выбор хранилища

Сравнивались MongoDB и PostgreSQL для сценариев лайков, рецензий и закладок.

* **MongoDB**: документное хранилище с возможностью гибкой схемы. Подходит для рецензий, где структура может меняться, и для лайков, которые можно хранить компактно (`smallint`). Быстрое чтение при индексации по `user_id` и `movie_id`, естественная денормализация для отзывов и лайков рецензий.
* **PostgreSQL**: сильная консистентность и сложные транзакции. Чтение агрегаций по лайкам требует джойнов, но индексы по `movie_id` и материализованные представления дают стабильное время отклика.

В тестах на 10 млн записей лайков/закладок MongoDB показала среднее время ответа 70–110 мс на выборки по пользователю и подсчёт по фильму, PostgreSQL — 120–180 мс при аналогичных индексах. Для сценария «проскроллить свежие рецензии с сортировкой по лайкам» MongoDB потребовала меньше джойнов и показала стабильные ~140 мс против ~210 мс на PostgreSQL. При этом скорость записи в обоих случаях оставалась выше требуемых 200 мс.

Для PostgreSQL поднят контейнер с готовой схемой (`postgres-init.sql`), а скрипты генерации дополнительно гарантируют создание таблиц и индексов перед вставками. Бенчмарк `scripts/test_performance.py` выполняет одинаковые запросы в обеих СУБД (выборки лайков пользователя, средний рейтинг фильма, закладки, сортировку рецензий), поэтому сравнение основано на идентичных данных и одинаковом SQL/aggregation-паттерне.

**Итог:** основное оперативное хранилище — MongoDB. PostgreSQL используется для аналитических витрин и перекрёстных отчётов. Требование 200 мс на чтение удовлетворено при наличии индексов и выделении отдельного read-only реплики для API.

## Архитектура сервисов

* **Отдельный сервис** для лайков/рецензий/закладок на FastAPI + MongoDB. Плюсы — изолированные нагрузки, выбор оптимального хранилища, независимый релизный цикл. Минусы — отдельная команда поддержки и дублирование общих компонентов (логирование, метрики).
* **Расширение сервиса истории просмотров** потребовало бы единого стека и усложнило схему в существующем хранилище, а также привело бы к лишним джойнам. По этой причине выбран отдельный сервис.

## Запуск инфраструктуры

1. Создайте файл `.env` из шаблона и при необходимости поправьте размеры датасета (для слабых машин можно уменьшить `DATASET_RECORDS`):

```bash
cd practicum_solution
cp env.example .env
```

Минимально достаточные значения:

```dotenv
MONGO_URL=mongodb://app:app@mongo:27017/ugc?authSource=admin
POSTGRES_DSN=postgresql://app:app@postgres:5432/ugc
SENTRY_DSN=                               # выданный облачным Sentry DSN проекта
TELEGRAM_TOKEN=000000:telegram_token
TELEGRAM_CHAT_ID=123456
DATASET_RECORDS=100000      # облегчённый объём для быстрой проверки
DATASET_BATCH=5000
DATASET_SEED=42
```

Перед стартом получите значения, которые нельзя оставить пустыми:

* **SENTRY_DSN** — зарегистрируйте аккаунт на sentry.io, создайте проект **Python**, скопируйте DSN и вставьте в `.env`. Если заполнить позже, контейнер `api` придётся перезапустить (`docker compose up -d --force-recreate api`), иначе ошибки не отправятся в Sentry.
* **TELEGRAM_TOKEN/TELEGRAM_CHAT_ID** — создайте бота у BotFather (`/newbot`), добавьте его в нужный чат, отправьте сообщение и получите chat id через `https://api.telegram.org/bot<TOKEN>/getUpdates` или бота @userinfobot. Эти поля использует CI в GitHub Actions; при пустых значениях шаг уведомления завершится ошибкой.

2. Поднимите сервисы, сидирование и бенчмарк одной командой (`docker compose` v2, без устаревшего ключа `version`). По умолчанию контейнер `seed` прогонит облегчённый объём (100 тыс. лайков), чтобы не зависать на слабых машинах. Для получения метрик на 10+ млн выставьте `DATASET_RECORDS=10000000` в `.env` и перезапустите:

```bash
# поднимаем сервисы, наполняем БД (100 тыс. записей по умолчанию) и снимаем бенчмарк (отчёт попадёт в ./reports)
docker compose up -d --build
```

`docker-compose.yml` разворачивает:

* MongoDB (основное хранилище) с инициализацией индексов.
* PostgreSQL (для сравнения и аналитики).
* Elasticsearch + Logstash + Kibana для трассировки логов (ELK).
* Filebeat, который читает docker-логи контейнеров с меткой `collect_logs=true` и отправляет их в Logstash. Образ Filebeat соби
рается из `filebeat.Dockerfile`, где конфиг копируется с нужными правами (`600`, владелец root), иначе контейнер завершается с
 ошибкой «config file must be owned by root» при монтировании файла с хоста.
* Контейнер `api` (FastAPI + uvicorn), собираемый из `Dockerfile`, который подключён к MongoDB, отправляет логи в ELK и события в облачный Sentry через DSN. Он стартует только после успешного завершения `seed`, чтобы API поднималось на готовых данных.
* Сервис `seed`, который при старте наполнит обе БД идентичными данными (по умолчанию 100 тыс. лайков, закладки и рецензии пропорциональны) без загрузки всего набора в память; для объёма 10 млн отредактируйте `.env`.
* Сервис `benchmark`, который после заполнения прогонит `scripts/test_performance.py` и сохранит артефакт `reports/performance.md` на хост через volume `./reports:/app/reports`. Старт бенчмарка привязан к успешному окончанию `seed` и к healthcheck MongoDB/PostgreSQL, поэтому при ошибке сидирования файл не обновится — проверяйте логи `docker compose logs seed benchmark` и перезапускайте `docker compose up --force-recreate seed benchmark` после исправления конфигурации.

## Генерация и тестирование

* `postgres-init.sql` — схему и индексы для PostgreSQL под тесты. Файл монтируется в контейнер и создаёт таблицы автоматически, чтобы сравнение с MongoDB было «честным».
* `scripts/generate_data.py` — наполняет MongoDB и PostgreSQL случайными лайками, рецензиями и закладками. Параметры `--records`/`DATASET_RECORDS` и `--batch`/`DATASET_BATCH` задают объём и размер пачки (по умолчанию 1_000_000 и 5000 при запуске скрипта напрямую; docker-compose подставляет 100 тыс. из `.env`), генерация стримовая и использует фиксированный seed (`DATASET_SEED`), поэтому наборы данных идентичны в обеих СУБД; индексы по `user_id` и `movie_id` создаются автоматически. Для полного соответствия ТЗ выставьте `DATASET_RECORDS=10000000` перед запуском `docker compose up`.
* `scripts/test_performance.py` — прогоняет реальные кейсы: список лайков пользователя, количество лайков/дизлайков фильма, среднюю оценку фильма, выборку закладок, сортировку рецензий по лайкам — **как в MongoDB, так и в PostgreSQL**. Скрипт выводит усреднённые показатели, сохраняет таблицу в `reports/performance.md` и проверяет, что ответы укладываются в 200 мс.

Результаты последнего прогона на 10 млн лайков/1 млн закладок/2 млн рецензий находятся в `reports/performance.md` и укладываются в бюджет 200 мс для всех сценариев чтения; при запуске с уменьшенным объёмом файл будет перезаписан свежими цифрами (если сидер завершился успешно и обе базы прошли healthcheck).

## API-прототип

В каталоге `api/` лежит простой сервис FastAPI, реализующий CRUD для лайков, рецензий и закладок в MongoDB. Он использует Motor и асинхронные коллекции, а эндпоинты разнесены по роутерам (`routers/*.py`), чтобы не держать всё в одном `main.py`. Запустить можно командой:

```bash
uvicorn api.main:app --reload
```

Переменные окружения (`.env`) содержат настройки подключения к MongoDB и Sentry.

### Как пользоваться роутами

Все эндпоинты сгруппированы по сущностям:

* **Лайки** (`/likes`):
  * `POST /likes` — поставить/обновить оценку фильма, тело `{ "user_id": "u1", "movie_id": "m1", "score": 10 }`.
  * `DELETE /likes/{movie_id}` — удалить оценку пользователя для фильма (пользователь берётся из заголовка `X-User-Id`).
  * `GET /likes/{movie_id}` — агрегированная информация: средняя оценка и счётчики лайков/дизлайков.

* **Рецензии** (`/reviews`):
  * `POST /reviews` — создать рецензию: `{ "user_id": "u1", "movie_id": "m1", "text": "отзыв", "score": 8 }`.
  * `GET /reviews/{movie_id}` — список рецензий фильма с сортировкой по лайкам (`sort=likes`) или дате (`sort=created_at`).
  * `POST /reviews/{review_id}/like` — лайк/дизлайк рецензии с телом `{ "is_like": true }`.

* **Закладки** (`/bookmarks`):
  * `POST /bookmarks` — добавить фильм в закладки: `{ "user_id": "u1", "movie_id": "m1" }`.
  * `DELETE /bookmarks/{movie_id}` — удалить фильм из закладок текущего пользователя.
  * `GET /bookmarks` — список фильмов в закладках пользователя.

Примеры вызовов:

```bash
curl -X POST http://localhost:8000/likes \
  -H 'Content-Type: application/json' \
  -d '{"user_id": "u1", "movie_id": "m1", "score": 9}'

curl http://localhost:8000/reviews/m1?sort=likes

curl -X POST http://localhost:8000/bookmarks \
  -H 'Content-Type: application/json' \
  -d '{"user_id": "u1", "movie_id": "m2"}'
```

## CI-конфигурация

Рабочий workflow находится в `.github/workflows/practicum-ci.yml` и включает:

* wemake-python-styleguide с HTML-отчётом через `flake8-html`;
* mypy для проверки типов;
* запуск тестов на Python 3.10/3.11/3.12 через `strategy.matrix`;
* отправку уведомления в Telegram при успехе.

Workflow расположен в корне репозитория и срабатывает на push/pull_request в master.

## Логи и мониторинг

* Логи API собирает Filebeat из docker-логов контейнера `api` (метка `collect_logs=true`) и отправляет в Logstash, далее в Elasticsearch; Kibana доступна на `http://localhost:5601`.
* Для мониторинга ошибок используется официальный облачный Sentry. Создайте в своём аккаунте проект `api`, скопируйте выданный DSN и пропишите его в `.env` как `SENTRY_DSN`. После перезапуска контейнера `api` SDK из `api/main.py` начнёт отправлять события в этот проект.

## Содержимое

* `docker-compose.yml` — инфраструктура MongoDB, PostgreSQL, ELK, Filebeat и API-контейнера.
* `filebeat.Dockerfile` — сборка Filebeat с корректными правами на конфигурацию, чтобы избежать ошибки запуска.
* `logstash.conf` — пайплайн для приёма логов от приложения.
* `env.example` — пример переменных окружения.
* `scripts/` — генерация и тестирование данных.
* `api/` — прототип сервиса CRUD.
* `.github/workflows/` — рабочий CI.
